{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header \n",
    "Author : Amina Matt and Yichen Wang  \n",
    "Date created : 14.10.2021  \n",
    "Date last modified : 14.10.2021  \n",
    "Python version : 3.8  \n",
    "Description : Text processing of the CARICOM Compilation Archive (CCA) https://louverture.ch/cca/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Natural Language Toolkit is a library for natural language programming in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aminamatt/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import nltk \n",
    "#nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.chunk import conlltags2tree\n",
    "from nltk.tree import Tree\n",
    "\n",
    "PATH = '/Users/aminamatt/Documents/Cours-2021/FDH/Colonial-heritage-in-Switzerland/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entities Recognition with NER Stanford "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('=', 'O'), ('>', 'O'), ('Hans', 'PERSON'), ('Conrad', 'PERSON'), ('Hottinger', 'PERSON'), ('’', 'O'), ('s', 'O'), ('business', 'O'), ('partner', 'O'), ('was', 'O'), ('Denis', 'PERSON'), ('de', 'PERSON'), ('Rougemont', 'PERSON'), ('(', 'O'), ('1759\\xad–1839', 'O'), (')', 'O'), ('from', 'O'), ('Saint-Aubin', 'LOCATION'), ('and', 'O'), ('Neuchâtel', 'LOCATION'), (',', 'O'), ('banker', 'O'), (',', 'O'), ('Prussian', 'MISC'), ('financial', 'O'), ('agent', 'O'), (',', 'O'), ('major', 'O'), ('Banque', 'ORGANIZATION'), ('de', 'ORGANIZATION'), ('France', 'ORGANIZATION'), ('shareholder', 'O'), ('and', 'O'), ('real', 'O'), ('estate', 'O'), ('owner', 'O'), ('in', 'O'), ('Paris', 'LOCATION'), ('and', 'O'), ('Berne', 'LOCATION'), ('.', 'O'), ('He', 'O'), ('bought', 'O'), ('the', 'O'), ('Hôtel', 'PERSON'), ('DuPeyrou', 'PERSON'), ('in', 'O'), ('Neuchâtel', 'LOCATION'), ('in', 'O'), ('1816', 'O'), ('.', 'O'), ('In', 'O'), ('1837', 'O'), (',', 'O'), ('his', 'O'), ('son', 'O'), ('Abraham', 'PERSON'), ('Denis', 'PERSON'), ('Alfred', 'PERSON'), ('de', 'PERSON'), ('Rougemont', 'PERSON'), ('(', 'O'), ('1802–1868', 'O'), (')', 'O'), (',', 'O'), ('who', 'O'), ('was', 'O'), ('a', 'O'), ('good', 'O'), ('friend', 'O'), ('of', 'O'), ('Heinrich', 'PERSON'), ('Escher', 'PERSON'), ('’', 'O'), ('s', 'O'), ('(', 'O'), ('1776–1853', 'O'), (')', 'O'), (',', 'O'), ('bought', 'O'), ('Schadau', 'ORGANIZATION'), ('Castle', 'ORGANIZATION'), ('and', 'O'), ('the', 'O'), ('adjoining', 'O'), ('large', 'O'), ('estate', 'O'), ('in', 'O'), ('Thun', 'PERSON'), ('BE', 'O'), ('and', 'O'), ('had', 'O'), ('the', 'O'), ('Castle', 'ORGANIZATION'), ('rebuilt', 'O'), ('in', 'O'), ('a', 'O'), ('style', 'O'), ('inspired', 'O'), ('by', 'O'), ('Tudor', 'MISC'), ('gothic', 'O'), ('and', 'O'), ('Loire', 'ORGANIZATION'), ('castles', 'O'), ('.', 'O'), ('His', 'O'), ('other', 'O'), ('son', 'O'), (',', 'O'), ('Rodolphe', 'PERSON'), ('Emile', 'PERSON'), ('Adolphe', 'PERSON'), ('de', 'PERSON'), ('Rougement', 'PERSON'), ('(', 'O'), ('1805–1844', 'O'), (')', 'O'), (',', 'O'), ('had', 'O'), ('bought', 'O'), ('castle', 'O'), ('Chartreuse', 'LOCATION'), ('on', 'O'), ('the', 'O'), ('opposite', 'O'), ('bank', 'O'), ('of', 'O'), ('the', 'O'), ('Aare', 'LOCATION'), ('river', 'O'), ('in', 'O'), ('Thun', 'PERSON'), ('in', 'O'), ('1831', 'O'), ('.', 'O'), ('The', 'O'), ('de', 'O'), ('Rougement', 'O'), ('family', 'O'), ('were', 'O'), ('related', 'O'), ('to', 'O'), ('the', 'O'), ('de', 'PERSON'), ('Pourtalès', 'PERSON'), ('and', 'O'), ('the', 'O'), ('de', 'PERSON'), ('Pury', 'PERSON'), ('families', 'O'), ('of', 'O'), ('Neuchâtel', 'LOCATION'), ('with', 'O'), ('their', 'O'), ('close', 'O'), ('ties', 'O'), ('to', 'O'), ('the', 'O'), ('transatlantic', 'O'), ('slavery', 'O'), ('system', 'O'), ('.', 'O'), ('1.2', 'O'), ('Bahamas', 'LOCATION')]\n"
     ]
    }
   ],
   "source": [
    "#Stanford NER \n",
    "NER_FOLDER = PATH+'NER-Standford/stanford-ner-2020-11-17'\n",
    "CLASSIFIER_PATH = NER_FOLDER+'/classifiers/'\n",
    "JAR_PATH = NER_FOLDER+'/stanford-ner.jar'\n",
    "\n",
    "#classifiers\n",
    "classifier_3 = 'english.all.3class.distsim.crf.ser.gz'#3 class model for recognizing locations, persons, and organizations\n",
    "classifier_4 = 'english.conll.4class.distsim.crf.ser.gz'#4 class model for recognizing locations, persons, organizations, and miscellaneous entities\n",
    "classifier_7 = 'english.muc.7class.distsim.crf.ser.gz' #7 class model for recognizing locations, persons, organizations, times, money, percents, and dates\n",
    "\n",
    "st = StanfordNERTagger(CLASSIFIER_PATH+classifier_4, JAR_PATH, encoding='utf-8')\n",
    "\n",
    "#Text retrieving\n",
    "caricom_sample = PATH+'Caricom_Archive_Sample.txt'\n",
    "caricom = PATH+'Caricom_Archive.txt'\n",
    "\n",
    "#Extracting named-entities\n",
    "text = open(caricom_sample, 'r').read()\n",
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the whole text is tagged. However the entities aren't grouped together. For example, a person full name is separate into two tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIO tagging for readable Named Entities (i.e. regrouped NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BIO](https://en.wikipedia.org/wiki/Inside–outside–beginning_(tagging)) tags are a way to regroup tokens, to make the output more readable. \n",
    "A person name with first and last name should be regroup by assigning  \n",
    " -B to the beginning of named entities  \n",
    " -I assigned to inside  \n",
    " -O assigned to other  \n",
    "This is done by checking the tokens just before and after the one of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function imported from \n",
    "# https://pythonprogramming.net/using-bio-tags-create-named-entity-lists/?completed=/testing-stanford-ner-taggers-for-speed/\n",
    "\n",
    "# Tag tokens with standard NLP BIO tags\n",
    "def bio_tagger(ne_tagged):\n",
    "\t\tbio_tagged = [] #empty list\n",
    "\t\tprev_tag = \"O\" #starting with a O tag\n",
    "\t\tfor token, tag in ne_tagged:\n",
    "\t\t\tif tag == \"O\": #O\n",
    "\t\t\t\tbio_tagged.append((token, tag))\n",
    "\t\t\t\tprev_tag = tag\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif tag != \"O\" and prev_tag == \"O\": # Begin NE\n",
    "\t\t\t\tbio_tagged.append((token, \"B-\"+tag))\n",
    "\t\t\t\tprev_tag = tag\n",
    "\t\t\telif prev_tag != \"O\" and prev_tag == tag: # Inside NE\n",
    "\t\t\t\tbio_tagged.append((token, \"I-\"+tag))\n",
    "\t\t\t\tprev_tag = tag\n",
    "\t\t\telif prev_tag != \"O\" and prev_tag != tag: # Adjacent NE\n",
    "\t\t\t\tbio_tagged.append((token, \"B-\"+tag))\n",
    "\t\t\t\tprev_tag = tag\n",
    "\t\treturn bio_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_text = bio_tagger(classified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the BIO tags we can recreate a tokens list with regrouped/readable named entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function imported from \n",
    "# https://pythonprogramming.net/using-bio-tags-create-named-entity-lists/?completed=/testing-stanford-ner-taggers-for-speed/\n",
    "\n",
    "# Create tree       \n",
    "def stanford_tree(bio_tagged):\n",
    "\ttokens, ne_tags = zip(*bio_tagged)\n",
    "\tpos_tags = [pos for token, pos in pos_tag(tokens)]\n",
    "\n",
    "\tconlltags = [(token, pos, ne) for token, pos, ne in zip(tokens, pos_tags, ne_tags)]\n",
    "\tne_tree = conlltags2tree(conlltags) #from BIO to tree format\n",
    "\treturn ne_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_text = stanford_tree(bio_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function imported from \n",
    "# https://pythonprogramming.net/using-bio-tags-create-named-entity-lists/?completed=/testing-stanford-ner-taggers-for-speed/\n",
    "\n",
    "# Parse named entities from tree\n",
    "def structure_ne(ne_tree):\n",
    "\tne = []\n",
    "\tfor subtree in ne_tree:\n",
    "\t\tif type(subtree) == Tree: # If subtree is a noun chunk, i.e. NE != \"O\"\n",
    "\t\t\tne_label = subtree.label()\n",
    "\t\t\tne_string = \" \".join([token for token, pos in subtree.leaves()])\n",
    "\t\t\tne.append((ne_string, ne_label))\n",
    "\treturn ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hans Conrad Hottinger', 'PERSON'),\n",
       " ('Denis de Rougemont', 'PERSON'),\n",
       " ('Saint-Aubin', 'LOCATION'),\n",
       " ('Neuchâtel', 'LOCATION'),\n",
       " ('Prussian', 'MISC'),\n",
       " ('Banque de France', 'ORGANIZATION'),\n",
       " ('Paris', 'LOCATION'),\n",
       " ('Berne', 'LOCATION'),\n",
       " ('Hôtel DuPeyrou', 'PERSON'),\n",
       " ('Neuchâtel', 'LOCATION'),\n",
       " ('Abraham Denis Alfred de Rougemont', 'PERSON'),\n",
       " ('Heinrich Escher', 'PERSON'),\n",
       " ('Schadau Castle', 'ORGANIZATION'),\n",
       " ('Thun', 'PERSON'),\n",
       " ('Castle', 'ORGANIZATION'),\n",
       " ('Tudor', 'MISC'),\n",
       " ('Loire', 'ORGANIZATION'),\n",
       " ('Rodolphe Emile Adolphe de Rougement', 'PERSON'),\n",
       " ('Chartreuse', 'LOCATION'),\n",
       " ('Aare', 'LOCATION'),\n",
       " ('Thun', 'PERSON'),\n",
       " ('de Pourtalès', 'PERSON'),\n",
       " ('de Pury', 'PERSON'),\n",
       " ('Neuchâtel', 'LOCATION'),\n",
       " ('Bahamas', 'LOCATION')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ne = structure_ne(tree_text)\n",
    "clean_ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From NE tree to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure NE list for each text is transformed into an entry in a dataframe. The goal is to have for each sample of text an entry with the *relevant* informations.  \n",
    "The difficult part is to sort the relevant informations. Which of the persons is the one of interest? Which location is the location where the organization or the person was involved? Which dates are the dates of interest? \n",
    "Here we deal only with the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>Location</th>\n",
       "      <th>Organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Loire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Loire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Person Location Organization\n",
       "0    NaN  Bahamas        Loire\n",
       "1    NaN  Bahamas        Loire\n",
       "2   test      NaN          NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.append({\n",
    "            'Person' :  'test'\n",
    "        },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>Location</th>\n",
       "      <th>Organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Person Location Organization\n",
       "0    NaN      NaN          NaN\n",
       "1    NaN      NaN          NaN\n",
       "2  test2      NaN          NaN\n",
       "3    NaN      NaN        test3\n",
       "4  test2      NaN          NaN\n",
       "5    NaN      NaN        test3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.append({\n",
    "            'Person' :  'test2'\n",
    "        },ignore_index=True)\n",
    "df = df.append({\n",
    "            'Organization' :  'test3'\n",
    "        },ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Person     Location      Organization\n",
      "0  Hans Conrad Hottinger          NaN               NaN\n",
      "1     Denis de Rougemont          NaN               NaN\n",
      "2                    NaN  Saint-Aubin               NaN\n",
      "3                    NaN    Neuchâtel               NaN\n",
      "5                    NaN          NaN  Banque de France\n"
     ]
    }
   ],
   "source": [
    "# for each paragraph we would like to have a JSON with \n",
    "# id, content, person, location, period range, organization\n",
    "\n",
    "#create the dataframe \n",
    "df = pd.DataFrame(columns=['Person','Location','Organization'], index=[])\n",
    "\n",
    "i=0\n",
    "for tokens in clean_ne:\n",
    "    if tokens[1] == 'PERSON':\n",
    "        df.loc[i,'Person']=  tokens[0]\n",
    "    if tokens[1] == 'LOCATION':    \n",
    "        df.loc[i,'Location'] =  tokens[0]\n",
    "    if tokens[1] == 'ORGANIZATION':    \n",
    "        df.loc[i,'Organization']=  tokens[0]\n",
    "    i= i + 1\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about multiple persons in a paragraph?\n",
    "    -> one ID per person with same organization groups etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.DataFrame({\n",
    "                     'id':[],\n",
    "                     'person':[],\n",
    "                     'location':[],\n",
    "                     'period':[],})\n",
    "dataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_list = []\n",
    "\n",
    "for ent in tokens.ents:\n",
    "    if ent.label_ == 'PERSON':\n",
    "        person_list.append(ent.text)\n",
    "        \n",
    "person_counts = Counter(person_list).most_common(20)\n",
    "df_person = pd.DataFrame(person_counts, columns =['text', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

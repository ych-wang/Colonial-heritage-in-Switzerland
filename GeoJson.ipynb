{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header \n",
    "Author : Amina Matt and Yichen Wang  \n",
    "Date created : 20.12.2021  \n",
    "Date last modified : 20.12.2021  \n",
    "Python version : 3.8  \n",
    "Description : Text processing of the CARICOM Compilation Archive (CCA) https://louverture.ch/cca/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import json\n",
    "import math #for isnan\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATHS\n",
    "DATA_FOLDER = './data/'\n",
    "caricom_sample = DATA_FOLDER +'Caricom_Archive_Sample_Schema1.txt'\n",
    "caricom = DATA_FOLDER +'Caricom_Archive.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./caricom_with_geoid.pkl\")\n",
    "#df.iloc[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates(col_lat,col_lon,or_lat,or_lon):\n",
    "    '''\n",
    "    Describe: function that create a geojson with data from dataframe\n",
    "    '''\n",
    "    geojson_structure['geometry']['coordinates'] =  [[col_lat, col_lon], [or_lat, or_lon]]\n",
    "    return geojson_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe processing\n",
    "#### Create a list in which new geojson are added for each dataframe entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 0\n",
    "# empty list\n",
    "geojson_with_coo_list = []\n",
    "\n",
    "# loop on dataframe\n",
    "for i in range(len(df)):\n",
    "    entry = df.iloc[i]\n",
    "    \n",
    "    #define structure \n",
    "    geojson_structure ={\"type\": \"Feature\",\n",
    "     \"properties\": {\n",
    "         \"person\": '',\n",
    "         \"date\": '',\n",
    "         \"origin\": '',\n",
    "         \"colonial_location\":'',\n",
    "         \"activities\":'',\n",
    "         \"full_entry\":'',\n",
    "     },\n",
    "     \"geometry\":\n",
    "         { \"type\": \"LineString\", \n",
    "          \"coordinates\": []\n",
    "         }\n",
    "    }\n",
    "    # get entry values\n",
    "    or_lat = entry['origin_latitude']\n",
    "    or_lon = entry['origin_longitude']\n",
    "    col_lat = entry['col_latitude']\n",
    "    col_lon = entry['col_longitude']\n",
    "\n",
    "    entry['confidence_date']\n",
    "    entry['confidence_origin']\n",
    "    entry['confidence_person']\n",
    "    # no lines if NaN values\n",
    "    if math.isnan(or_lat) or  math.isnan(or_lon) or  math.isnan(col_lat) or  math.isnan(col_lon) :\n",
    "        iter +=1\n",
    "        continue\n",
    "    else :   \n",
    "        # create geojson with coordinates\n",
    "        geojson_with_coo = add_coordinates(or_lon,or_lat,col_lon,col_lat)\n",
    "        geojson_structure['properties']['person'] =  entry['person']\n",
    "        geojson_structure['properties']['date'] =  entry['date']\n",
    "        geojson_structure['properties']['origin'] =  entry['origin']\n",
    "        geojson_structure['properties']['activities'] =  entry['activities']\n",
    "        geojson_structure['properties']['full_entry'] =  entry['whole_entry']\n",
    "        geojson_structure['properties']['colonial_location'] =  entry['colonial_Location']\n",
    "\n",
    "        # add to list\n",
    "        geojson_with_coo_list.append(geojson_with_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 106 entries for the geojsons, 221 were dropped from the initial dataset of length 327 because they had no geographical coordinates.\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(geojson_with_coo_list)} entries for the geojsons, {iter} were dropped from the initial dataset of length {len(df)} because they had no geographical coordinates.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON for the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_json = {\"type\": \"FeatureCollection\",\"features\": []}\n",
    "overall_json['features']= geojson_with_coo_list\n",
    "#overall_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"lines.json\", \"w\")\n",
    "a_file = json.dump(overall_json, a_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to understand why some of the data don't have geographical coordinates and thus canno't be visualized.\n",
    "In this case we cannot visualize if we don't have an origin location. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list is all the origin for which  we weren't able to retrieve geographical informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16                None\n",
       "17                None\n",
       "18                None\n",
       "19                None\n",
       "20                None\n",
       "            ...       \n",
       "322            Germany\n",
       "323            Neuthal\n",
       "324            Rümlang\n",
       "325       Lichtensteig\n",
       "326    TumeglDomleschg\n",
       "Name: origin, Length: 221, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_geo_inf = df[df['origin_as_found'].isnull()]['origin']\n",
    "no_geo_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 'Saint-Aubin', 'Bournens', 'Bourmens', 'Echallens',\n",
       "       'Obersimmental', 'Bâle', '', 'Noraz', 'Le Locle', 'Rehetobel',\n",
       "       'Brazil', 'Morges', 'Ropraz', 'Gourgy', 'Africa', 'Lelienburg',\n",
       "       'Bürglen', 'Burgdorf', 'Thurgau', 'Treytorrens', 'Speicher',\n",
       "       'Walenstadt', 'La Tour-de-Peilz', 'Lutry', 'Murten', 'Switzerland',\n",
       "       'La Rochelle', 'Versoix', 'Sonvillier', 'Schftland',\n",
       "       'Saint-Domingue', 'Hunziker', 'Solothurn', 'Aargau', 'Dornach',\n",
       "       'Graubünden', 'Jamaica', 'Rougement', 'Mtier', 'Bischofszell',\n",
       "       'Unterseen BE', 'Couvet', 'Nantes', 'Zofingen', 'Klosters',\n",
       "       'Saint-Saphorin', 'Saint-Lgier-La Chisaz', 'Saint-Sulpice',\n",
       "       'La Cluse', 'Schwyz', 'Vendlincourt', 'Lenzburg', 'Avenches',\n",
       "       'Martinique', 'Guttannen', 'North Carolina', 'South Carolina',\n",
       "       'Bilten', 'Tenessee', 'Henau', 'BerneVaud', 'Frschels', 'Aa',\n",
       "       'Benken', 'Moudon', 'Java', 'Celigny', 'Soglio', 'Germany',\n",
       "       'Neuthal', 'Rümlang', 'Lichtensteig', 'TumeglDomleschg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_geo_inf.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 221 origin with no geographic information, which represents 74 different locations.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(no_geo_inf)} origin with no geographic information, which represents {len(no_geo_inf.unique())} different locations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "originEmpty = len(df[df['origin']==''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On this 221 entries without geographical coordinates, 9 were not retrieved to start with\n"
     ]
    }
   ],
   "source": [
    "print(f'On this {len(no_geo_inf)} entries without geographical coordinates, {originEmpty} were not retrieved to start with')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['confidence_date']= df['confidence_date'].apply(lambda x : float(x))\n",
    "df['confidence_origin']= df['confidence_origin'].apply(lambda x : float(x))\n",
    "df['confidence_person']= df['confidence_person'].apply(lambda x : float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average values for confidence level are the following : \n",
      " For date :   37.6605504587156\n",
      " For person : 51.8868501529052 \n",
      " For origin : 52.0488379204893\n"
     ]
    }
   ],
   "source": [
    "mean_conf_date = df.confidence_date.describe()['mean']\n",
    "mean_conf_origin = df.confidence_origin.describe()['mean']\n",
    "mean_conf_person = df.confidence_person.describe()['mean']\n",
    "\n",
    "print(f'The average values for confidence level are the following : \\n For date :   {mean_conf_date}\\n For person : {mean_conf_person} \\n For origin : {mean_conf_origin}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

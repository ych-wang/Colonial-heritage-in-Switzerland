{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header \n",
    "Author : Amina Matt and Yichen Wang  \n",
    "Date created : 14.10.2021  \n",
    "Date last modified : 21.11.2021  \n",
    "Python version : 3.8  \n",
    "Description : Text processing of the CARICOM Compilation Archive (CCA) https://louverture.ch/cca/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do List\n",
    "- [X] check number items\n",
    "- [X] to JSON \n",
    "- [X] JSON fix None answer\n",
    "- [ ] Add colonial location\n",
    "- [ ] JSON cleaning of parenthesis in names?\n",
    "- [ ] save NER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import nltk #Natural Language Toolkit is a natural language programming library\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.chunk import conlltags2tree\n",
    "from nltk.tree import Tree\n",
    "import random\n",
    "from pandas.io.json import json_normalize\n",
    "import pickle\n",
    "\n",
    "\n",
    "#PATHS\n",
    "DATA_FOLDER = './data/'\n",
    "caricom_sample = DATA_FOLDER +'Caricom_Archive_Sample_Schema1.txt'\n",
    "caricom = DATA_FOLDER +'Caricom_Archive.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text separation into items \n",
    "In the primary text source, each item is separated by a return and the '=>' starting string. Each item references a different actor of colonial entreprise. Separating each of them into items helps us to differentiate the extraction depending on the scheme they follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: path for the .txt file \n",
    "#Output: list of string, where each element is an item, i.e. a separate entry in the document of origin\n",
    "#Requirements: -\n",
    "#Description: separate the items based on the '=>' string that characterize a new entry\n",
    "def divide_items(textFilePath):\n",
    "    f = open(textFilePath,\"r\")\n",
    "    item = []\n",
    "    flagTOC = False\n",
    "    for line in f: \n",
    "        \n",
    "        if (line == '1 CARICOM MEMBER STATES\\n') :\n",
    "            flagTOC = True #the TOC has been full read\n",
    "            #print('the TOC has been read')\n",
    "            \n",
    "        if flagTOC : #check if line is a TOC entry\n",
    "            if (line[0].isdigit()) and  (line[1] == '.') and (line[2].isdigit()) : #we have a subTOC entry, level n.n\n",
    "                colonialIndex = line[0:3]\n",
    "                colonialIndex = colonialIndex.replace('\\n','')\n",
    "                #print('the colonial index is ' + str(colonialIndex))\n",
    "              \n",
    "        if (line != '\\n'):\n",
    "            if (line[0] == '=') and (line[1] == '>'):\n",
    "                item_text = ''\n",
    "                while (line != '\\n'):\n",
    "                    item_text = item_text + line\n",
    "                    line = f.readline()\n",
    "                #Once the item is read we add its colonial index that corresponds to a TOC entry\n",
    "                #We add the index at the end to retrieve it easily\n",
    "                item_text = item_text.replace('\\n','')    \n",
    "                item_text = item_text + (' '+colonialIndex)\n",
    "                #print('The text item now has the colonial index'+item_text)\n",
    "                item.append(item_text)\n",
    "    f.close()\n",
    "    return item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 464 items in total.\n"
     ]
    }
   ],
   "source": [
    "text_items = divide_items(caricom)\n",
    "items_total = len(text_items)\n",
    "print(f'There are {len(text_items)} items in total.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is one text item:\n",
      "=> The second protagonist set temporarily in a colonial context by Gottfried Keller (1819–1890), renowned Swiss novelist from Zurich, is Martin Salander («Martin Salander», 1886). He comes from the provincial town of Münsterburg in Switzerland, becomes very rich in Brazil with the cultivation and trade of coffee and tobacco, loses everything to a fraudulent financial scheme, returns to Brazil and regains his wealth. His son also travels to Brazil to continue his father’s business there: Arnold Salander expands his father’s estate and finds a capable Swiss «for operation and supervision», who will soon be involved in the business transactions. Although the only way to get rich twice in Brazil through coffee and tobacco is by being involved in chattel slavery, a professor of German literature at Zurich University in 2020 speculated vaguely if Salander might have become rich through emigration or perhaps as an engineer. Slavery as a possibility was not even mentioned. 4.1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'This is one text item:\\n{text_items[random.randrange(len(text_items))]}.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.1', 'Antigua and Barbuda'),\n",
       " ('1.2', 'Bahamas'),\n",
       " ('1.3', 'Barbados'),\n",
       " ('1.4', 'Dominica'),\n",
       " ('1.5', 'Grenada'),\n",
       " ('1.6',\n",
       "  'Guyana (Guiana): Dutch/English colonies «ara», «Essequibo», and «Berbice»'),\n",
       " ('1.6', '1 Berbice'),\n",
       " ('1.6', '2 Demerara (Demerrara, Demerary)'),\n",
       " ('1.6', '3 Essequibo'),\n",
       " ('1.7', 'Haiti (colony «Saint-Domingue»)'),\n",
       " ('1.7', '1 Economic'),\n",
       " ('1.7', '2 Military'),\n",
       " ('1.7', '3 Ideological'),\n",
       " ('1.8', 'Jamaica'),\n",
       " ('1.9', 'Montserrat'),\n",
       " ('1.1', ' St. Vincent & The Grenadines'),\n",
       " ('1.1', ' Suriname'),\n",
       " ('1.1', ' Trinidad and Tobago'),\n",
       " ('2.1', 'Cuba'),\n",
       " ('2.2',\n",
       "  'Netherlands Antilles (colonies «Aruba», «Bonaire», «Curaçao», «St. Eustacius»)'),\n",
       " ('2.3', 'French West Indies (colonies «Guiana», «Guadeloupe», «Martinique»)'),\n",
       " ('2.4',\n",
       "  'Danish West Indies (colonies «St. John», «St. Croix», and «St. Thomas»)'),\n",
       " ('2.5', 'Venezuela'),\n",
       " ('2.6', 'Bermudas'),\n",
       " ('3.1', ' North America (the Thirteen Colonies and the United States)'),\n",
       " ('3.1', '1 Alabama'),\n",
       " ('3.1', '2 Arkansas'),\n",
       " ('3.1', '3 California'),\n",
       " ('3.1', '4 Carolinas'),\n",
       " ('3.1', '5 Florida'),\n",
       " ('3.1', '6 Georgia'),\n",
       " ('3.1', '7 Kentucky'),\n",
       " ('3.1', '8 Louisiana'),\n",
       " ('3.1', '9 Mississippi'),\n",
       " ('3.1', '10 New York'),\n",
       " ('3.1', '11 Tennessee'),\n",
       " ('3.1', '12 Texas'),\n",
       " ('3.1', '13 Virginia'),\n",
       " ('3.2',\n",
       "  'Brazil (Colonial Brazil, United Kingdom with Portugal, independent empire)'),\n",
       " ('3.3', 'Southern Africa'),\n",
       " ('3.4', 'East Indies'),\n",
       " ('4.1',\n",
       "  'Anti-Black Racism and Ideologies Relevant to Caribbean Economic Space'),\n",
       " ('4.2', 'Marine Navigation'),\n",
       " ('4.3', 'African and European Logistics')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tocList_func(textFilePath):\n",
    "    f = open(textFilePath,\"r\")\n",
    "    tocList = []\n",
    "    for line in f: \n",
    "        if (line == '1 CARICOM MEMBER STATES\\n') :\n",
    "            break\n",
    "        else : \n",
    "            if (line[0].isdigit()) and  (line[1] == '.') and (line[2].isdigit())  : #we have a subTOC entry, level n.n\n",
    "                toc = (line[0:3],line[4:-1])\n",
    "                #print(toc)\n",
    "                tocList.append(toc)\n",
    "    f.close()\n",
    "    return tocList\n",
    "tocList = tocList_func(caricom)   \n",
    "tocList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entities Recognition with NER Stanford \n",
    "The first objective is to extract information of interest from the text. In this case we are interested in person's names, locations and activities. The first step towards this goal is to use Named Entities Recognition to recognize which words contain the information we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('=', 'O'), ('>', 'O'), ('François', 'PERSON'), ('Aimé', 'PERSON'), ('Louis', 'PERSON'), ('Dumoulin', 'PERSON'), ('(', 'O'), ('1753-1834', 'O'), (')', 'O'), ('from', 'O'), ('Vevey', 'LOCATION'), ('(', 'O'), ('Canton', 'LOCATION'), ('of', 'O'), ('BerneVaud', 'O'), (')', 'O'), ('left', 'O'), ('Switzerland', 'LOCATION'), ('at', 'O'), ('the', 'O'), ('age', 'O'), ('of', 'O'), ('20', 'O'), ('for', 'O'), ('the', 'O'), ('Caribbean', 'LOCATION'), ('and', 'O'), ('lived', 'O'), ('on', 'O'), ('Grenada', 'LOCATION'), ('1773–1783', 'O'), ('.', 'O'), ('He', 'O'), ('worked', 'O'), ('as', 'O'), ('a', 'O'), ('painter', 'O'), (',', 'O'), ('secretary', 'O'), ('to', 'O'), ('the', 'O'), ('governor', 'O'), ('of', 'O'), ('the', 'O'), ('island', 'O'), (',', 'O'), ('and', 'O'), ('merchant', 'O'), ('.', 'O'), ('In', 'O'), ('1778', 'DATE'), (',', 'O'), ('he', 'O'), ('was', 'O'), ('pressed', 'O'), ('into', 'O'), ('the', 'O'), ('English', 'O'), ('army', 'O'), ('of', 'O'), ('Governor', 'O'), ('MacCartney', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "#Stanford NER \n",
    "NER_FOLDER = './NER-Standford/stanford-ner-2020-11-17'\n",
    "CLASSIFIER_PATH = NER_FOLDER+'/classifiers/'\n",
    "JAR_PATH = NER_FOLDER+'/stanford-ner.jar'\n",
    "\n",
    "#classifiers\n",
    "classifier_3 = 'english.all.3class.distsim.crf.ser.gz'#3 class model for recognizing locations, persons, and organizations\n",
    "classifier_4 = 'english.conll.4class.distsim.crf.ser.gz'#4 class model for recognizing locations, persons, organizations, and miscellaneous entities\n",
    "classifier_7 = 'english.muc.7class.distsim.crf.ser.gz' #7 class model for recognizing locations, persons, organizations, times, money, percents, and dates\n",
    "\n",
    "st = StanfordNERTagger(CLASSIFIER_PATH+classifier_7, JAR_PATH, encoding='utf-8')\n",
    "\n",
    "\n",
    "\n",
    "#Extracting named-entities\n",
    "text = open(caricom_sample, 'r').read()\n",
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the whole text is tagged. However the entities aren't grouped together. For example, a person full name is separate into two tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIO tagging for readable Named Entities (i.e. regrouped NE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BIO](https://en.wikipedia.org/wiki/Inside–outside–beginning_(tagging)) tags are a way to regroup tokens, to make the output more readable. \n",
    "A person name with first and last name should be regroup by assigning  \n",
    " -B to the beginning of named entities  \n",
    " -I assigned to inside  \n",
    " -O assigned to other  \n",
    "This is done by checking the tokens just before and after the one of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function imported from \n",
    "# https://pythonprogramming.net/using-bio-tags-create-named-entity-lists/?completed=/testing-stanford-ner-taggers-for-speed/\n",
    "\n",
    "# Tag tokens with standard NLP BIO tags\n",
    "def bio_tagger(ne_tagged):\n",
    "\t\tbio_tagged = [] #empty list\n",
    "\t\tprev_tag = \"O\" #starting with a O tag\n",
    "\t\tfor token, tag in ne_tagged:\n",
    "\t\t\tif tag == \"O\": #O\n",
    "\t\t\t\tbio_tagged.append((token, tag))\n",
    "\t\t\t\tprev_tag = tag\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif tag != \"O\" and prev_tag == \"O\": # Begin NE\n",
    "\t\t\t\tbio_tagged.append((token, \"B-\"+tag))\n",
    "\t\t\t\tprev_tag = tag\n",
    "\t\t\telif prev_tag != \"O\" and prev_tag == tag: # Inside NE\n",
    "\t\t\t\tbio_tagged.append((token, \"I-\"+tag))\n",
    "\t\t\t\tprev_tag = tag\n",
    "\t\t\telif prev_tag != \"O\" and prev_tag != tag: # Adjacent NE\n",
    "\t\t\t\tbio_tagged.append((token, \"B-\"+tag))\n",
    "\t\t\t\tprev_tag = tag\n",
    "\t\treturn bio_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('=', 'O'),\n",
       " ('>', 'O'),\n",
       " ('François', 'B-PERSON'),\n",
       " ('Aimé', 'I-PERSON'),\n",
       " ('Louis', 'I-PERSON'),\n",
       " ('Dumoulin', 'I-PERSON'),\n",
       " ('(', 'O'),\n",
       " ('1753-1834', 'O'),\n",
       " (')', 'O'),\n",
       " ('from', 'O'),\n",
       " ('Vevey', 'B-LOCATION'),\n",
       " ('(', 'O'),\n",
       " ('Canton', 'B-LOCATION'),\n",
       " ('of', 'O'),\n",
       " ('BerneVaud', 'O'),\n",
       " (')', 'O'),\n",
       " ('left', 'O'),\n",
       " ('Switzerland', 'B-LOCATION'),\n",
       " ('at', 'O'),\n",
       " ('the', 'O'),\n",
       " ('age', 'O'),\n",
       " ('of', 'O'),\n",
       " ('20', 'O'),\n",
       " ('for', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Caribbean', 'B-LOCATION'),\n",
       " ('and', 'O'),\n",
       " ('lived', 'O'),\n",
       " ('on', 'O'),\n",
       " ('Grenada', 'B-LOCATION'),\n",
       " ('1773–1783', 'O'),\n",
       " ('.', 'O'),\n",
       " ('He', 'O'),\n",
       " ('worked', 'O'),\n",
       " ('as', 'O'),\n",
       " ('a', 'O'),\n",
       " ('painter', 'O'),\n",
       " (',', 'O'),\n",
       " ('secretary', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('governor', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('island', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('merchant', 'O'),\n",
       " ('.', 'O'),\n",
       " ('In', 'O'),\n",
       " ('1778', 'B-DATE'),\n",
       " (',', 'O'),\n",
       " ('he', 'O'),\n",
       " ('was', 'O'),\n",
       " ('pressed', 'O'),\n",
       " ('into', 'O'),\n",
       " ('the', 'O'),\n",
       " ('English', 'O'),\n",
       " ('army', 'O'),\n",
       " ('of', 'O'),\n",
       " ('Governor', 'O'),\n",
       " ('MacCartney', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_text = bio_tagger(classified_text)\n",
    "bio_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the BIO tags we can recreate a tokens list with regrouped/readable named entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function imported from \n",
    "# https://pythonprogramming.net/using-bio-tags-create-named-entity-lists/?completed=/testing-stanford-ner-taggers-for-speed/\n",
    "\n",
    "# Create tree       \n",
    "def stanford_tree(bio_tagged):\n",
    "\ttokens_raw, ne_tags = zip(*bio_tagged)\n",
    "\ttokens = [word for word in tokens_raw if word]\n",
    "\tpos_tags = [pos for token, pos in pos_tag(tokens)]\n",
    "\n",
    "\tconlltags = [(token, pos, ne) for token, pos, ne in zip(tokens, pos_tags, ne_tags)]\n",
    "\tne_tree = conlltags2tree(conlltags) #from BIO to tree format\n",
    "\treturn ne_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_text = stanford_tree(bio_text)\n",
    "tree_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function imported from \n",
    "# https://pythonprogramming.net/using-bio-tags-create-named-entity-lists/?completed=/testing-stanford-ner-taggers-for-speed/\n",
    "\n",
    "# Parse named entities from tree\n",
    "def structure_ne(ne_tree):\n",
    "\tne = []\n",
    "\tfor subtree in ne_tree:\n",
    "\t\tif type(subtree) == Tree: # If subtree is a noun chunk, i.e. NE != \"O\"\n",
    "\t\t\tne_label = subtree.label()\n",
    "\t\t\tne_string = \" \".join([token for token, pos in subtree.leaves()])\n",
    "\t\t\tne.append((ne_string, ne_label))\n",
    "\t\telse:\n",
    "\t\t\tne_label = 'O'\n",
    "\t\t\tne_string = subtree[0]\n",
    "\t\t\tne.append((ne_string, ne_label))           \n",
    "\treturn ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('=', 'O'),\n",
       " ('>', 'O'),\n",
       " ('François Aimé Louis Dumoulin', 'PERSON'),\n",
       " ('(', 'O'),\n",
       " ('1753-1834', 'O'),\n",
       " (')', 'O'),\n",
       " ('from', 'O'),\n",
       " ('Vevey', 'LOCATION'),\n",
       " ('(', 'O'),\n",
       " ('Canton', 'LOCATION'),\n",
       " ('of', 'O'),\n",
       " ('BerneVaud', 'O'),\n",
       " (')', 'O'),\n",
       " ('left', 'O'),\n",
       " ('Switzerland', 'LOCATION'),\n",
       " ('at', 'O'),\n",
       " ('the', 'O'),\n",
       " ('age', 'O'),\n",
       " ('of', 'O'),\n",
       " ('20', 'O'),\n",
       " ('for', 'O'),\n",
       " ('the', 'O'),\n",
       " ('Caribbean', 'LOCATION'),\n",
       " ('and', 'O'),\n",
       " ('lived', 'O'),\n",
       " ('on', 'O'),\n",
       " ('Grenada', 'LOCATION'),\n",
       " ('1773–1783', 'O'),\n",
       " ('.', 'O'),\n",
       " ('He', 'O'),\n",
       " ('worked', 'O'),\n",
       " ('as', 'O'),\n",
       " ('a', 'O'),\n",
       " ('painter', 'O'),\n",
       " (',', 'O'),\n",
       " ('secretary', 'O'),\n",
       " ('to', 'O'),\n",
       " ('the', 'O'),\n",
       " ('governor', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('island', 'O'),\n",
       " (',', 'O'),\n",
       " ('and', 'O'),\n",
       " ('merchant', 'O'),\n",
       " ('.', 'O'),\n",
       " ('In', 'O'),\n",
       " ('1778', 'DATE'),\n",
       " (',', 'O'),\n",
       " ('he', 'O'),\n",
       " ('was', 'O'),\n",
       " ('pressed', 'O'),\n",
       " ('into', 'O'),\n",
       " ('the', 'O'),\n",
       " ('English', 'O'),\n",
       " ('army', 'O'),\n",
       " ('of', 'O'),\n",
       " ('Governor', 'O'),\n",
       " ('MacCartney', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ne = structure_ne(tree_text)\n",
    "clean_ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_text(text):\n",
    "    tokenized_text = word_tokenize(text)\n",
    "    classified_text = st.tag(tokenized_text)\n",
    "    bio_text = bio_tagger(classified_text)\n",
    "    tree_text = stanford_tree(bio_text)\n",
    "    ner_item = structure_ne(tree_text)\n",
    "    return ner_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From NE tree to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure NE list for each text is transformed into an entry in a dataframe. The goal is to have for each sample of text an entry with the *relevant* informations.  \n",
    "The difficult part is to sort the relevant informations. Which of the persons is the one of interest? Which location is the location where the organization or the person was involved? Which dates are the dates of interest? \n",
    "Here we deal only with the transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use schema 1 **(*name* (date) from *origin*)** to retrieve JSON names, origins and dates attributes in the text item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIGHT BE USELESS \n",
    "#Input:\n",
    "#Output: \n",
    "#Requirements: \n",
    "#Description: \n",
    "def is_date(dateString):\n",
    "    return any(s.isdigit() for s in dateString)\n",
    "#Works for (1731-1820)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: item is a single entry from text source 1 with NER tags (characterized by the '=>' starting string)\n",
    "#Output: True is the text is structured as schema 1, False otherwise\n",
    "#Requirements: is_date() function\n",
    "#Description: Test if the first elements of a text match the schema 1. Namely, does the first words match the  **Name** (*date*) from *city* pattern.\n",
    "def schema1_test(item):\n",
    "    tags = [x[1] for x in item]\n",
    "    text_middle= [x[0] for x in item]\n",
    "    #start and end of piece of interest\n",
    "    schema1 = False\n",
    "    try:\n",
    "        person_Index = tags.index('PERSON')\n",
    "    except ValueError:\n",
    "        person_Index = 1 #default\n",
    "        print(\"List does not contain value\")\n",
    "    try: \n",
    "        location_Index = tags.index('LOCATION')\n",
    "    except ValueError:\n",
    "        print(\"List does not contain value\")\n",
    "        location_Index = 0 #default\n",
    "    if person_Index < location_Index:\n",
    "        ner_middle = item[person_Index+1:location_Index-1]\n",
    "    #digit test\n",
    "    digit_test = any(x.isdigit() for x in text_middle)\n",
    "    #parenthesis test\n",
    "    if digit_test :\n",
    "        schema1 = ('(' and ')') in text_middle#parenthesis test\n",
    "\n",
    "    return schema1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function test\n",
    "schema1_test(ner_text(text_items[80]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From NER to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: item is a single entry from text source 1 with NER tags (characterized by the '=>' starting string)\n",
    "#Output: A JSON string with Person,Date,Location keys if is the text is structured as schema 1, None otherwise\n",
    "#Requirements: is_date() function\n",
    "#Description: Test if the first elements of a text match the schema 1. \n",
    "#Namely, does the first words match the  **Name** (*date*) from *city* pattern.\n",
    "#If it matches schema1 it returns a dictionary \n",
    "def schema1_JSON(item):\n",
    "    #Default\n",
    "    schema1 = False\n",
    "    s1item_JSON = None\n",
    "    #Separate text and tags\n",
    "    text = [x[0] for x in item]\n",
    "    tags = [x[1] for x in item]\n",
    "    \n",
    "    ##--Start and end of piece of interest, i.e. ...'PERSON'.....'LOCATION'--##\n",
    "    try:\n",
    "        person_Index = tags.index('PERSON')\n",
    "        person = text[person_Index]\n",
    "    except ValueError:\n",
    "        person_Index = -1 #default\n",
    "        print(\"Item does not contain a PERSON value\")\n",
    "        \n",
    "   \n",
    "    #Location can be found with LOCATION tags. But it should, according to schema 1 also be just after the 'from'.. confidence will tell us if it is both sources or not\n",
    "    #Origin Method 1\n",
    "    try:\n",
    "        #Case 1: 1 word location\n",
    "        origin_Index_method1 = text.index('from')\n",
    "        origin_1 = text[origin_Index_method1+1]\n",
    "        #Case 2: 2 words location, e.g. Le Locle \n",
    "        #print('First letter' + text[origin_Index_method1+2][0])\n",
    "        if (text[origin_Index_method1+2][0]).isupper() : \n",
    "            origin_1 = origin_1 +' '+ text[origin_Index_method1+2]\n",
    "        #Case 3: the City of Location, e.g. the City of Geneva\n",
    "        if (text[origin_Index_method1+2]) == 'City' : \n",
    "            origin_1 = text[origin_Index_method1+4]\n",
    "            \n",
    "        #print('The origin index using from gives origin as :' + origin_1)\n",
    "    except ValueError:\n",
    "        print(\"Item does not contain any 'form' string\")\n",
    "        origin_1 = -1 #default\n",
    "    \n",
    "    \n",
    "    #Origin Method2\n",
    "    try: \n",
    "        origin_Index_method2 = tags.index('LOCATION')\n",
    "    except ValueError:\n",
    "        print(\"Item does not contain a LOCATION value\")\n",
    "        origin_Index_method2 = -1 #default\n",
    "   \n",
    "\n",
    "    #Check if both methods give the same answers\n",
    "    o_confidence = (origin_Index_method1 == origin_Index_method2)\n",
    "        \n",
    "    #If there are PERSON and LOCATION values, with PERSON first we continue the schema1 test\n",
    "    if person_Index < origin_Index_method1 and person_Index > 0 and origin_Index_method1 > 0 :\n",
    "        #Define part in between PER and LOC tags\n",
    "        ner_middle = item[person_Index+1:origin_Index_method1]\n",
    "        #print('This is the person value'+str(item[person_Index]))\n",
    "        #print('This is the location value'+str(item[origin_Index_method1+1]))\n",
    "        #print('This is the in NER between'+str(ner_middle))\n",
    "        text_middle = [x[0] for x in ner_middle]\n",
    "        #print('This is the in text between'+str(ner_middle))\n",
    "        \n",
    "        #Parenthesis test\n",
    "        try:\n",
    "            par1_Index = text_middle.index('(')\n",
    "        except ValueError:\n",
    "            par1_Index = -1 #default\n",
    "        #print(\"par 1 index \" + str(par1_Index))\n",
    "              \n",
    "        try:\n",
    "            par2_Index = text_middle.index(')')\n",
    "        except ValueError:\n",
    "            par2_Index = -1 #default\n",
    "        #print(\"par 2 index \" + str(par2_Index))\n",
    "        \n",
    "        #If there are parenthesis\n",
    "        if par1_Index < par2_Index and par2_Index >= 0 and par1_Index >= 0 :\n",
    "            date_par = text_middle[par1_Index+1:par2_Index]\n",
    "            #print('This is the text in between parenthesis ' +str(date_par))\n",
    "            #SKIPPING DIGIT TEST\n",
    "            #digit test\n",
    "            #digit_test = any(x.isdigit() for x in str(date_par))\n",
    "            #print('The digit test results : '+str(digit_test))\n",
    "            #Save informations from schema 1\n",
    "            #if digit_test :\n",
    "                \n",
    "                #retrieve date\n",
    "             #   date = ''\n",
    "              #  date_split = str(date_par).split('–')\n",
    "              #  for x in str(date_split):\n",
    "              #      if x.isdigit():\n",
    "             #           date = date +' '+ x\n",
    "            date = str(date_par[0])\n",
    "            #print('The retrieved date is ' + date)\n",
    "           \n",
    "        \n",
    "            #Create a JSON dictionary\n",
    "            s1item_JSON = {\n",
    "                'person' : person,\n",
    "                'date': date,\n",
    "                'origin': origin_1,\n",
    "                'o_confidence':o_confidence\n",
    "                #'field':NA\n",
    "            }\n",
    "    return s1item_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example where the function fails due to bad NER\n",
      "=> Marx Rütimeyer‏‎ (b. 1647) from Vinelz (Canton of Berne) worked as a goldminer in the Bahamas and died there. 1.2\n",
      "Item does not contain a PERSON value\n",
      "\n",
      "\n",
      "This is an example where the function works\n",
      "=> Jean Huguenin (1685–1740) from Le Locle (Canton of Neuchâtel) moved to Holland with Swiss troops. His son Jean Roulof Huguenin (1731-1764) became ensign in the regiment Douglas, a military unit which had been sent to Berbice to suppress the slave rising of 1763. Lieutenant Colonel Robert Douglas was a Scotsman at the service of the Dutch army and the second in command in the expedition against the rebellious slaves. Huguenin died in Berbice and is buried in Fort Nassau. 1.6\n",
      "{'person': 'Jean Huguenin', 'date': '1685–1740', 'origin': 'Le Locle ( Canton of Neuchâtel', 'o_confidence': False}\n"
     ]
    }
   ],
   "source": [
    "#Function test\n",
    "print('This is an example where the function fails due to bad NER')\n",
    "n = 4\n",
    "print(text_items[n])\n",
    "schema1_JSON(ner_text(text_items[n]))\n",
    "\n",
    "print('\\n\\nThis is an example where the function works')\n",
    "n = 30\n",
    "print(text_items[n])\n",
    "print(schema1_JSON(ner_text(text_items[n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: item is a single entry from text source 1 with NER tags (characterized by the '=>' starting string)\n",
    "#Output: A JSON string with Person,Date,Location keys if is the text is structured as schema 1, None otherwise\n",
    "#Requirements: is_date() function\n",
    "#Description: Test if the first elements of a text match the schema 1. \n",
    "#Namely, does the first words match the  => In date, **Name** from *city* pattern.\n",
    "#If it matches schema1 it returns a dictionary \n",
    "def schema2_JSON(item):\n",
    "    #Default\n",
    "    schema2 = False\n",
    "    s2item_JSON = None\n",
    "    #Separate text and tags\n",
    "    text = [x[0] for x in item]\n",
    "    tags = [x[1] for x in item]\n",
    "    \n",
    "    #'In YEAR' test \n",
    "    inYear = (text[2] == 'In') and (len(text[3]) == 4) and (text[3].isdigit())\n",
    "    #print('This item looks like an schema 2 item '+str(inYear) + str(text[2:4]))\n",
    "    if inYear : \n",
    "        date = text[3]\n",
    "    \n",
    "    ##--Start and end of piece of interest, i.e. ...'PERSON'.....'LOCATION'--##\n",
    "    try:\n",
    "        person_Index = tags.index('PERSON')\n",
    "        person = text[person_Index]\n",
    "        print(\"Item does contain a PERSON value\")\n",
    "    except ValueError:\n",
    "        person_Index = -1 #default\n",
    "        print(\"Item does not contain a PERSON value\")\n",
    "    \n",
    "    #Location can be found with LOCATION tags. But it should, according to schema 2 also be just after the 'from'.. confidence will tell us if it is both sources or not\n",
    "    #Origin Method 1\n",
    "    try:\n",
    "        #Case 1: 1 word location\n",
    "        origin_Index_method1 = text.index('from')\n",
    "        origin_1 = text[origin_Index_method1+1]\n",
    "        #Case 2: 2 words location, e.g. Le Locle \n",
    "        print('First letter' + text[origin_Index_method1+2][0])\n",
    "        if (text[origin_Index_method1+2][0]).isupper() : \n",
    "            origin_1 = origin_1 +' '+ text[origin_Index_method1+2]\n",
    "        #Case 3: the City of Location, e.g. the City of Geneva\n",
    "        if (text[origin_Index_method1+2]) == 'City' : \n",
    "            origin_1 = text[origin_Index_method1+4]\n",
    "            \n",
    "        print('The origin index using from gives origin as :' + origin_1)\n",
    "    except ValueError:\n",
    "        print(\"Item does not contain any 'from' string\")\n",
    "        origin_1 = -1 #default\n",
    "    \n",
    "    \n",
    "    #Origin Method2\n",
    "    try: \n",
    "        origin_Index_method2 = tags.index('LOCATION')\n",
    "    except ValueError:\n",
    "        print(\"Item does not contain a LOCATION value\")\n",
    "        origin_Index_method2 = -1 #default\n",
    "        \n",
    "    #Check if both methods give the same answers\n",
    "    o_confidence = (origin_Index_method1 == origin_Index_method2)\n",
    "\n",
    "\n",
    "    #Create a JSON dictionary\n",
    "    s1item_JSON = {\n",
    "        'person' : person,\n",
    "        'date': date,\n",
    "        'origin': origin_1,\n",
    "        'o_confidence':o_confidence\n",
    "        #'field':NA\n",
    "    }\n",
    "\n",
    "    return s1item_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's try schema 2\n",
      "\n",
      "=> In 1767, one H. Werndli from Zurich, employed as a surgeon in Berbice, made a gift of plants and seeds to the Zurich Botanical Gardens. In 1773, he sent the Zurich Naturalist Society a collection of reptiles (e.g. the embryo of an armadillo preserved in alcohol) and of «American snakes». 1.6\n",
      "Item does contain a PERSON value\n",
      "First letter,\n",
      "The origin index using from gives origin as :Zurich\n",
      "{'person': 'H. Werndli', 'date': '1767', 'origin': 'Zurich', 'o_confidence': False}\n"
     ]
    }
   ],
   "source": [
    "print('Let\\'s try schema 2\\n')\n",
    "n = 45\n",
    "print(text_items[n])\n",
    "print(schema2_JSON(ner_text(text_items[n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(x.isdigit() for x in '1685–1740')\n",
    "sep = '1685–1740'.split('–')\n",
    "any(x.isdigit() for x in sep[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_and_tags(item):\n",
    "    #Default\n",
    "    schema1 = False\n",
    "    s1item_JSON = None\n",
    "    #Separate text and tags\n",
    "    text = [x[0] for x in item]\n",
    "    tags = [x[1] for x in item]\n",
    "    return text,tags\n",
    "\n",
    "\n",
    "def person_index(text,tags):\n",
    "    ##--Start and end of piece of interest, i.e. ...'PERSON'.....'LOCATION'--##\n",
    "    try:\n",
    "        person_Index = tags.index('PERSON')\n",
    "        #print(\"Item does contain a PERSON value\"+str(text[person_Index]))\n",
    "    except ValueError:\n",
    "        person_Index = -1 #default\n",
    "        print(\"Item does not contain a PERSON value\")\n",
    "    return person_Index\n",
    "\n",
    "def origin_location_index(text,tags):\n",
    "    #The origin location can be found with LOCATION tags. But it should, according to schema 2 also be just after the 'from'.. confidence will tell us if it is both sources or not\n",
    "    #Origin Method 1\n",
    "    try:\n",
    "        #Case 1: 1 word origin location\n",
    "        origin_Index_method1 = text.index('from')\n",
    "        origin_1 = text[origin_Index_method1+1]\n",
    "        #Case 2: 2 words origin location, e.g. Le Locle \n",
    "        #print('First letter' + text[origin_Index_method1+2][0])\n",
    "        if (text[origin_Index_method1+2][0]).isupper() : \n",
    "            origin_1 = origin_1 +' '+ text[origin_Index_method1+2]\n",
    "        #Case 3: the City of Location, e.g. the City of Geneva\n",
    "        if ((text[origin_Index_method1+2]) == 'City') or  ((text[origin_Index_method1+2]) == 'Canton'): \n",
    "            origin_1 = text[origin_Index_method1+4]\n",
    "        #print('The origin index using from gives origin as :' + origin_1)\n",
    "    except ValueError:\n",
    "        print(\"Item does not contain any 'from' string\")\n",
    "        origin_1 = -1 #default\n",
    "        origin_Index_method1 = -1\n",
    "    \n",
    "    \n",
    "    #Origin Method2\n",
    "    try: \n",
    "        origin_Index_method2 = tags.index('LOCATION')\n",
    "    except ValueError:\n",
    "        print(\"Item does not contain a LOCATION value\")\n",
    "        origin_Index_method2 = -1 #default\n",
    "        \n",
    "    #Check if both methods give the same answers\n",
    "    o_confidence = (origin_Index_method1 == origin_Index_method2)\n",
    "    return origin_Index_method1,origin_1,o_confidence\n",
    "  \n",
    "def person_location(person_Index,origin_Index_method1) :\n",
    "    #If there are PERSON and LOCATION values, with PERSON first we continue the schema1 test\n",
    "    flag = (person_Index < origin_Index_method1) and (person_Index > 0) and (origin_Index_method1 > 0)\n",
    "    return flag    \n",
    "    \n",
    "\n",
    "def date(text,tags,person_Index,origin_Index_method1):\n",
    "    #SCHEMA 2\n",
    "    #In YEAR' test \n",
    "    inYear = (text[2] == 'In') and (len(text[3]) == 4) and (text[3].isdigit())\n",
    "    #print('This item looks like an schema 2 item '+str(inYear) + str(text[2:4]))\n",
    "    if inYear : \n",
    "        date = text[3]\n",
    "        return date\n",
    "    \n",
    "    else :\n",
    "    #SCHEMA 1\n",
    "    #(date)\n",
    "        #Define part in between PER and LOC tags\n",
    "        ner_middle = item[person_Index+1:origin_Index_method1]\n",
    "        text_middle = text[person_Index+1:origin_Index_method1]\n",
    "\n",
    "        #Parenthesis test\n",
    "        try:\n",
    "            par1_Index = text_middle.index('(')\n",
    "        except ValueError:\n",
    "            par1_Index = -1 #default\n",
    "\n",
    "        try:\n",
    "            par2_Index = text_middle.index(')')\n",
    "        except ValueError:\n",
    "            par2_Index = -1 #default\n",
    "\n",
    "        #If there are parenthesis\n",
    "        if par1_Index < par2_Index and par2_Index >= 0 and par1_Index >= 0 :\n",
    "            date_par = text_middle[par1_Index+1:par2_Index]\n",
    "            date = str(date_par[0])\n",
    "            return date\n",
    "        else :\n",
    "            return None\n",
    "\n",
    "def colonial_location(text,tocList) :\n",
    "    tocFromText = text[len(text)-1]#the last item is the TOC entry \n",
    "    #print(tocFromText)\n",
    "    tocListIndex = [x[0] for x in tocList]\n",
    "    colonialLoc = tocList[tocListIndex.index(tocFromText)][1]\n",
    "    \n",
    "    return colonialLoc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colonial_activites(text):\n",
    "    # Colonial activities\n",
    "    trading = ['cotton', 'indigo', 'sugar', 'tobacco', 'textile', 'merchant']\n",
    "    military = ['captain','lieutenant','commander','regiment', 'rebellion', 'troops']\n",
    "    plantation = ['plantation', 'plantations']\n",
    "    slave_trade = ['slave ship', 'slave-ship']\n",
    "    result = []\n",
    "    for word in text:\n",
    "        if word in trading:\n",
    "            result.append('trading')\n",
    "        if word in military:\n",
    "            result.append('military')\n",
    "        if word in plantation:\n",
    "            result.append('plantation owner')\n",
    "        if word in slave_trade:\n",
    "            result.append('slave trade')\n",
    "\n",
    "    return None if len(result) == 0 else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_and_tags(ner_items[12])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plantation owner', 'plantation owner']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colonial_activites(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'= > The Peschiers were Huguenots from the south of France who settled in Geneva . Pierre Peschier ( 1688–1766 ) was a pharmacist with links to England . His son Jean ( b . 1735 ) settled in Grenada , possibly as a member of the British military , where he married Rose de Belgens from a family rich plantation owners . His younger brother Henri ( b . 1741 ) joined him later , and , financed by their brother Jean Antoine , who still lived in Geneva , the two Peschier brothers acquired a plantation of 192 acres called Bonne Chance with at least 80 slaves . They paid 12,600 livres for it . The brothers also became merchants in the capital and chief port of St.George ’ s . Henri ( Henry ) then decided to emigrate to Trinidad , where he arrived in 1781 with some slaves . 1.5'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ner_items = []\n",
    "# for item in text_items:\n",
    "#     ner_item = ner_text(item)\n",
    "#     ner_items.append(ner_item)\n",
    "# len(ner_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save and load ner_items in pickle\n",
    "# pickle.dump(ner_items, open( \"ner_items.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_items = pickle.load( open( \"ner_items.p\", \"rb\" ) )\n",
    "len(ner_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonList= []\n",
    "i = 0\n",
    "s1 = 0\n",
    "for item in ner_items:\n",
    "        #nerItem = ner_text(item)\n",
    "        text_tags = text_and_tags(item)\n",
    "        personIndex = person_index(text_tags[0],text_tags[1])\n",
    "        origin_info = origin_location_index(text_tags[0],text_tags[1]) #origin_Index_method1,origin,o_confidence\n",
    "\n",
    "        #Test if it will be one of the two schemas\n",
    "        if person_location(personIndex,origin_info[0]) :\n",
    "            person = text_tags[0][personIndex]\n",
    "            origin = origin_info[1]\n",
    "            o_confidence = origin_info[2]\n",
    "            \n",
    "            #Retrieve date according to schema1 or schema2 if no date then None\n",
    "            dateValue = date(text_tags[0],text_tags[1],personIndex,origin_info[0])\n",
    "            \n",
    "            #Retrieve colonial location\n",
    "            colonialLoc = colonial_location(text_tags[0],tocList)\n",
    "            \n",
    "            activites = colonial_activites(text_tags[0])\n",
    "            \n",
    "            #Create a JSON dictionary\n",
    "            item_JSON = {\n",
    "                'person' : person,\n",
    "                'date': dateValue,\n",
    "                'origin': origin,\n",
    "                'o_confidence':o_confidence,\n",
    "                'colonial_Location': colonialLoc,\n",
    "                'activities': activites\n",
    "            }\n",
    "            jsonList.append(item_JSON)\n",
    "        #print(item_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jsonList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Paul Coulon (1731 – 1820) from Neuchâtel (NW Switzerland), together with Jacques Louis Pourtalès (1722–1814) from Neuchâtel and Johann Jakob Thurneysen (1729–1784) from Bâle, owned the plantations Bellair (coffee and cocoa), Mont Saint–Jean (coffee), La Conférence (sugar), Clavier, and Larcher. Until 1797, they produced sugar, coffee, cocoa, and cotton with about 100 to 200 slaves on each plantation. The plantations were administered by François und Pierre de Meuron from Neuchâtel. One of them married a woman qualified in the racist terminology of the island a «quarteronne», daughter of white father and a mulatto mother and took her home with him to Neuchâtel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>date</th>\n",
       "      <th>origin</th>\n",
       "      <th>o_confidence</th>\n",
       "      <th>colonial_Location</th>\n",
       "      <th>activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Paul Coulon</td>\n",
       "      <td>1731</td>\n",
       "      <td>Neuchâtel ( NW Switzerland )</td>\n",
       "      <td>False</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>[plantation owner, trading, trading, trading, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        person  date                        origin  o_confidence  \\\n",
       "8  Paul Coulon  1731  Neuchâtel ( NW Switzerland )         False   \n",
       "\n",
       "  colonial_Location                                         activities  \n",
       "8           Grenada  [plantation owner, trading, trading, trading, ...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caricomDataRaw.loc[caricomDataRaw['person']=='Paul Coulon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person': 'Paul Coulon',\n",
       " 'date': '1731',\n",
       " 'origin': 'Neuchâtel ( NW Switzerland )',\n",
       " 'o_confidence': False,\n",
       " 'colonial_Location': 'Grenada',\n",
       " 'activities': ['plantation owner',\n",
       "  'trading',\n",
       "  'trading',\n",
       "  'trading',\n",
       "  'plantation owner',\n",
       "  'plantation owner']}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonList[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['trading', 'plantation owner', 'plantation owner', 'trading']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caricomDataRaw.loc[caricomDataRaw['person']=='Henry Peschier']['activities'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From JSONs to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform JSON list into a dataframe \n",
    "caricomDataRaw = pd.json_normalize(jsonList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "- Remove all the duplicates\n",
    "- If some entries have the samed person we need to merge or remove one of the entry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>date</th>\n",
       "      <th>origin</th>\n",
       "      <th>o_confidence</th>\n",
       "      <th>colonial_Location</th>\n",
       "      <th>activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Heinrich Escher</td>\n",
       "      <td>1815</td>\n",
       "      <td>Zurich</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>[plantation owner, plantation owner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Heinrich Studer</td>\n",
       "      <td>1779-1831</td>\n",
       "      <td>Winterthur</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>[plantation owner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Johannes Köhli‏‎</td>\n",
       "      <td>1773–1814</td>\n",
       "      <td>Biel</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>[trading]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Karl Wilhelm Scherb</td>\n",
       "      <td>1780–1827</td>\n",
       "      <td>Bischofszell</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>[trading]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Johann Ulrich Zellweger</td>\n",
       "      <td>1804–1871</td>\n",
       "      <td>the</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>[plantation owner, trading, trading, plantatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Jacob Jakob</td>\n",
       "      <td>1850</td>\n",
       "      <td>the</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>[plantation owner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Philippe Robert-Tissot</td>\n",
       "      <td>None</td>\n",
       "      <td>Neuchâtel</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>[plantation owner, plantation owner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Eine Selbstschau »</td>\n",
       "      <td>1771-1848</td>\n",
       "      <td>Unterseen BE</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Favre</td>\n",
       "      <td>None</td>\n",
       "      <td>Couvet</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>[slave trade]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Charles Rossel</td>\n",
       "      <td>1822</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>False</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>[slave trade, slave trade]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      person       date        origin  o_confidence  \\\n",
       "120          Heinrich Escher       1815        Zurich         False   \n",
       "121          Heinrich Studer  1779-1831    Winterthur         False   \n",
       "122         Johannes Köhli‏‎  1773–1814          Biel         False   \n",
       "123      Karl Wilhelm Scherb  1780–1827  Bischofszell         False   \n",
       "124  Johann Ulrich Zellweger  1804–1871           the         False   \n",
       "125              Jacob Jakob       1850           the         False   \n",
       "126   Philippe Robert-Tissot       None     Neuchâtel         False   \n",
       "127       Eine Selbstschau »  1771-1848  Unterseen BE         False   \n",
       "128                    Favre       None        Couvet         False   \n",
       "129           Charles Rossel       1822        Nantes         False   \n",
       "\n",
       "    colonial_Location                                         activities  \n",
       "120              Cuba               [plantation owner, plantation owner]  \n",
       "121              Cuba                                 [plantation owner]  \n",
       "122              Cuba                                          [trading]  \n",
       "123              Cuba                                          [trading]  \n",
       "124              Cuba  [plantation owner, trading, trading, plantatio...  \n",
       "125              Cuba                                 [plantation owner]  \n",
       "126              Cuba               [plantation owner, plantation owner]  \n",
       "127              Cuba                                               None  \n",
       "128              Cuba                                      [slave trade]  \n",
       "129              Cuba                         [slave trade, slave trade]  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(raw_Data):\n",
    "    tmp = raw_Data.drop_duplicates(inplace=True)\n",
    "    clean_Data = tmp\n",
    "    return clean_Data\n",
    "   \n",
    "    \n",
    "i = 120\n",
    "caricomDataRaw.iloc[i:i+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Zurich\n",
       "1          Saint-Aubin\n",
       "2               Zurich\n",
       "3         Schaffhausen\n",
       "4               Africa\n",
       "            ...       \n",
       "290        a St.Gallen\n",
       "291              Berne\n",
       "292                  a\n",
       "293           a Geneva\n",
       "294    TumeglDomleschg\n",
       "Name: origin, Length: 295, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caricomDataRaw['origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>date</th>\n",
       "      <th>origin</th>\n",
       "      <th>o_confidence</th>\n",
       "      <th>colonial_Location</th>\n",
       "      <th>activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grafen Karl von Zinzendorf</td>\n",
       "      <td>None</td>\n",
       "      <td>Schaffhausen</td>\n",
       "      <td>False</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>[trading, trading, trading, trading, trading, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samuel Müller</td>\n",
       "      <td>None</td>\n",
       "      <td>Africa</td>\n",
       "      <td>False</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anton Schulthess</td>\n",
       "      <td>None</td>\n",
       "      <td>a Zurich</td>\n",
       "      <td>False</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>[trading, military]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jean-Antoine Bertrand (</td>\n",
       "      <td>None</td>\n",
       "      <td>Geneva</td>\n",
       "      <td>False</td>\n",
       "      <td>Dominica</td>\n",
       "      <td>[trading, plantation owner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Jean Henri (</td>\n",
       "      <td>None</td>\n",
       "      <td>where</td>\n",
       "      <td>False</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>[trading]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Carl Vogt ( 1817–1895 )</td>\n",
       "      <td>None</td>\n",
       "      <td>Germany</td>\n",
       "      <td>False</td>\n",
       "      <td>Anti-Black Racism and Ideologies Relevant to C...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Martin Salander</td>\n",
       "      <td>None</td>\n",
       "      <td>the Dutch</td>\n",
       "      <td>False</td>\n",
       "      <td>Anti-Black Racism and Ideologies Relevant to C...</td>\n",
       "      <td>[military]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Jan Willem ( Baron</td>\n",
       "      <td>None</td>\n",
       "      <td>a St.Gallen</td>\n",
       "      <td>False</td>\n",
       "      <td>African and European Logistics</td>\n",
       "      <td>[plantation owner]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Saint Domingue</td>\n",
       "      <td>None</td>\n",
       "      <td>Berne</td>\n",
       "      <td>False</td>\n",
       "      <td>African and European Logistics</td>\n",
       "      <td>[trading, trading, trading, trading, trading, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Johann Viktor Travers von Ortenstein ( 1721–17...</td>\n",
       "      <td>None</td>\n",
       "      <td>TumeglDomleschg</td>\n",
       "      <td>False</td>\n",
       "      <td>African and European Logistics</td>\n",
       "      <td>[military, military]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                person  date           origin  \\\n",
       "3                           Grafen Karl von Zinzendorf  None     Schaffhausen   \n",
       "4                                        Samuel Müller  None           Africa   \n",
       "6                                     Anton Schulthess  None         a Zurich   \n",
       "7                              Jean-Antoine Bertrand (  None           Geneva   \n",
       "11                                        Jean Henri (  None            where   \n",
       "..                                                 ...   ...              ...   \n",
       "276                            Carl Vogt ( 1817–1895 )  None          Germany   \n",
       "279                                    Martin Salander  None        the Dutch   \n",
       "290                                 Jan Willem ( Baron  None      a St.Gallen   \n",
       "291                                     Saint Domingue  None            Berne   \n",
       "294  Johann Viktor Travers von Ortenstein ( 1721–17...  None  TumeglDomleschg   \n",
       "\n",
       "     o_confidence                                  colonial_Location  \\\n",
       "3           False                                           Barbados   \n",
       "4           False                                           Barbados   \n",
       "6           False                                           Barbados   \n",
       "7           False                                           Dominica   \n",
       "11          False                                            Grenada   \n",
       "..            ...                                                ...   \n",
       "276         False  Anti-Black Racism and Ideologies Relevant to C...   \n",
       "279         False  Anti-Black Racism and Ideologies Relevant to C...   \n",
       "290         False                     African and European Logistics   \n",
       "291         False                     African and European Logistics   \n",
       "294         False                     African and European Logistics   \n",
       "\n",
       "                                            activities  \n",
       "3    [trading, trading, trading, trading, trading, ...  \n",
       "4                                                 None  \n",
       "6                                  [trading, military]  \n",
       "7                          [trading, plantation owner]  \n",
       "11                                           [trading]  \n",
       "..                                                 ...  \n",
       "276                                               None  \n",
       "279                                         [military]  \n",
       "290                                 [plantation owner]  \n",
       "291  [trading, trading, trading, trading, trading, ...  \n",
       "294                               [military, military]  \n",
       "\n",
       "[84 rows x 6 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caricomDataRaw.loc[caricomDataRaw['date'].values == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Zurich', 'Saint-Aubin', 'Schaffhausen', 'Africa', 'Geneva',\n",
       "       'a Zurich', 'Neuchâtel ( NW Switzerland )', 'Vevey', 'St.Gallen',\n",
       "       'where', 'Brazil', 'Bâle', 'Lausanne',\n",
       "       'Le Locle ( Canton of Neuchâtel', 'a Geneva', 'the', 'church',\n",
       "       'Lelienburg', 'Bürglen', 'Burgdorf ( Canton of Berne )', 'Basel',\n",
       "       'an Yverdon', 'Thurgau', 'Treytorrens ( Payerne', 'his',\n",
       "       'Speicher', 'Walenstadt', 'Aarau', 'a', 'Bournens',\n",
       "       'La Tour-de-Peilz', 'Lutry ( Canton of Vaud', 'a St.Gallen',\n",
       "       'Neuchâtel', 'Murten', 'Switzerland',\n",
       "       'St. Gallen ( E Switzerland )', 'La Rochelle', 'Versoix',\n",
       "       'Sonvillier', 'Schöftland ( Canton', 'Saint-Domingue', 'trade',\n",
       "       'Berne', 'Le Locle', 'a Neuchâtel', 'Hunziker', 'Solothurn',\n",
       "       'Aargau', 'Dornach', '1824', 'Lucerne',\n",
       "       'Graubünden ( E Switzerland )', 'Jamaica', 'Rougement', 'Yverdon',\n",
       "       'Morges', 'Môtier', 'Bourmens', 'Echallens', 'Obersimmental',\n",
       "       '1738–1744', 'Noréaz', '1796',\n",
       "       'the Vallée de Joux ( Canton of BerneVaud', 'Rehetobel',\n",
       "       'Ropraz ( Canton of BerneVaud', 'Gourgy', '1813', 'Winterthur',\n",
       "       'Biel', 'Bischofszell', 'Unterseen BE', 'Couvet', 'Nantes',\n",
       "       'Zofingen', 'Klosters ( Canton of Graubünden )', 'Fribourg',\n",
       "       'the City of Berne', 'Saint-Saphorin', 'Saint-Légier-La Chiésaz',\n",
       "       'the Swiss', 'Saint-Sulpice', 'La Cluse', 'Schwyz',\n",
       "       'Vendlincourt ( Canton of Berne', 'Lenzburg', 'Chur', 'Avenches',\n",
       "       'tropical West Africa', 'a Huguenot', '1770–1772', 'Martinique',\n",
       "       'a Schaffhausen', 'Guttannen', 'North Carolina', 'a Swiss',\n",
       "       'Bilten ( Canton of Glarus', 'a Bernese', 'St Imier', 'Felsberg',\n",
       "       'Appenzell Ausserrhoden', '1852', 'a NeuchâtelBerne',\n",
       "       'South Carolina', 'Bilten', 'Tenessee', 'an', 'Henau',\n",
       "       'Biel ( Berne', 'the Canton of Glarus', 'BerneVaud', 'Fräschels',\n",
       "       'Aa', 'Benken', 'the Pondichéry', 'a St.GallenThurgau', 'there',\n",
       "       'Moudon', 'Java', 'Celigny ( Canton of Geneva )', 'Zug', '1818',\n",
       "       'which', '1825–1830', 'Soglio', 'all', 'fellow Swiss', 'Germany',\n",
       "       'the Dutch', 'Neuthal ( Canton of Zurich )', 'danger', 'Rümlang',\n",
       "       'the Dominican Republic', 'Lichtensteig', 'TumeglDomleschg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caricomDataRaw['origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Antigua and Barbuda', 'Barbados', 'Dominica', 'Grenada',\n",
       "       'Guyana (Guiana): Dutch/English colonies «ara», «Essequibo», and «Berbice»',\n",
       "       'Haiti (colony «Saint-Domingue»)', 'Jamaica', 'Montserrat', 'Cuba',\n",
       "       'Netherlands Antilles (colonies «Aruba», «Bonaire», «Curaçao», «St. Eustacius»)',\n",
       "       'French West Indies (colonies «Guiana», «Guadeloupe», «Martinique»)',\n",
       "       'Danish West Indies (colonies «St. John», «St. Croix», and «St. Thomas»)',\n",
       "       'Venezuela', 'Bermudas',\n",
       "       ' North America (the Thirteen Colonies and the United States)',\n",
       "       'Brazil (Colonial Brazil, United Kingdom with Portugal, independent empire)',\n",
       "       'Southern Africa', 'East Indies',\n",
       "       'Anti-Black Racism and Ideologies Relevant to Caribbean Economic Space',\n",
       "       'Marine Navigation', 'African and European Logistics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caricomDataRaw['colonial_Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>date</th>\n",
       "      <th>origin</th>\n",
       "      <th>o_confidence</th>\n",
       "      <th>colonial_Location</th>\n",
       "      <th>activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samuel Müller</td>\n",
       "      <td>None</td>\n",
       "      <td>Africa</td>\n",
       "      <td>False</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          person  date  origin  o_confidence colonial_Location activities\n",
       "4  Samuel Müller  None  Africa         False          Barbados       None"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caricomDataRaw.iloc[4:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Get location when mentioned further to deal with : from the city of..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use section name to retrieve JSON colonial location attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use predefined categories to retrieve the JSON type attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old version of schema 1 test\n",
    "This version is outdated. To restrictive it gets only 18 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: item is a single entry from text source 1 with NER tags (characterized by the '=>' starting string)\n",
    "#Output: True is the text is structured as schema 1, False otherwise\n",
    "#Requirements: is_date() function\n",
    "#Description: Test if the first elements of a text match the schema 1. Namely, does the first words match the  **Name** (*date*) from *city* pattern.\n",
    "def schema1_test(item): \n",
    "    testValue = (item[2][1] == ('PERSON' or 'ORGANIZATION)')) and (item[3][0] == '(') and (is_date(item[4][0]) == True) and (item[5][0] == ')') and (item[6][0] == 'from') and (item[7][1] == 'LOCATION')\n",
    "    return testValue\n",
    "\n",
    "schema1_test(clean_ne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about multiple persons in a paragraph?\n",
    "    -> one ID per person with same organization groups etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = pd.DataFrame({\n",
    "                     'id':[],\n",
    "                     'person':[],\n",
    "                     'location':[],\n",
    "                     'period':[],})\n",
    "dataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_list = []\n",
    "\n",
    "for ent in tokens.ents:\n",
    "    if ent.label_ == 'PERSON':\n",
    "        person_list.append(ent.text)\n",
    "        \n",
    "person_counts = Counter(person_list).most_common(20)\n",
    "df_person = pd.DataFrame(person_counts, columns =['text', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
